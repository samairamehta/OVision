{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"papermill":{"default_parameters":{},"duration":15680.995323,"end_time":"2021-10-16T21:08:27.584475","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-10-16T16:47:06.589152","version":"2.3.3"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.113256,"end_time":"2021-10-16T16:47:13.199907","exception":false,"start_time":"2021-10-16T16:47:13.086651","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PATH_TO_DATA_TRAIN = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/5\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/5\"\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/5\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/5\"\n\n\nPATH_TO_DATA_TRAIN = \"/kaggle/input/train-val-test-zoom/train_set_53/7\"\nPATH_TO_DATA_TEST = \"/kaggle/input/train-val-test-zoom/test_set_11_updated/7\"\nPATH_TO_DATA_VAL = \"/kaggle/input/train-val-test-zoom/test_set_11/7\"\n\n#PATH_TO_DATA_VAL = \"/kaggle/input/train-val-test-zoom/val_set_16/7\"\n\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/train-val-test-zoom/train_set_53/8\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/train-val-test-zoom/test_set_11/8\"\n#PATH_TO_DATA_VAL = \"/kaggle/input/train-val-test-zoom/val_set_16/8\"\n\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/8\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/8\"\n\n#this one\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/8\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/8\"\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/7\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/7\"\n\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/6\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/train-zoom-onebyone/kaggle_train_data_zoom/6\"\n\n\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/6\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/6\"\n\n#PATH_TO_DATA_TRAIN = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/7\"\n#PATH_TO_DATA_TEST = \"/kaggle/input/test-zoom-onebyone/kaggle_test_data_zoom/7\"\n\n\n#PATH_TO_DATA_TEST = \"data/CRC-VAL-HE-7K\"","metadata":{"papermill":{"duration":0.03635,"end_time":"2021-10-16T16:47:13.266449","exception":false,"start_time":"2021-10-16T16:47:13.230099","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 32 batch size = 47% on untrained 1 of 12 epoch model with no frozen\n#batch_size_train =  32\n#experimenting with a larger batch size, on frozen layer \n# on a full frozen and only dense 512-256, took 27% in 28/3771 iterations 1st epoch\n#batch_size_train =  64\n\n# large batch size 256 causes 10% warning, 16GB = 128\n#batch_size_train =  256\n\n\n# try 128 -> 77%\n#batch_size_train =  128\n\n\n# try 64 ->  may go upto 79%, after 4 epoch 77%\n#batch_size_train =  64\n\n\n# try 32 ->  may go upto 81%, after 3 epoch 79.3%\nbatch_size_train =  32\n\nbatch_size_test = 1\n\n## alternate code to select certain number of images\nimport os \nimages = [] \nlabels =[] \nfor sub_dir in os.listdir(PATH_TO_DATA_TRAIN): \n  image_list=os.listdir(os.path.join(PATH_TO_DATA_TRAIN,sub_dir)) #list of all image names in the directory \n  image_list = list(map(lambda x:os.path.join(sub_dir,x),image_list)) \n  #print(\"initial image list =%d\", len(image_list))\n  #print(len(image_list[0:19000]))\n  #im_0 = image_list[0]\n  #print(len(im_0))\n  #im_1 = image_list[1]\n  #print(len(im_1))\n  #im_2 = image_list[2]\n  #print(len(im_2))\n  #im_3 = image_list[3]\n  #print(len(im_3))\n  #im_4 = image_list[4]\n  #print(len(im_4))\n  #im_5 = image_list[5]\n  #print(len(im_5))\n  images.extend(image_list[0:100])\n  #print(len(images))\n\n#forcing to take only 19K image from each\n  labels.extend([sub_dir]*len(image_list[0:100]))\n  #print(image_list)\n  #print(len(image_list[0:100]))\n  #print(temp)\n  #exit\n  #labels.extend([sub_dir]*len(image_list))\n\n  print(\"number of images = %d\", len(images))\n  #print(images)\n\ndf = pd.DataFrame({\"Images\":images,\"Labels\":labels})      \ndf = df.sample(frac=1).reset_index(drop=True) # To shuffle the data \ndf = df.head(500) # to take the subset of data (I'm taking 100 from it)\n#df = df.head(76000) # to take the subset of data (I'm taking 100 from it)\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=50,\n    validation_split = 0.1\n    )\n\n#test_datagen = ImageDataGenerator(\n#    rescale=1./255,\n#    validation_split = 0.1\n#    )\n\n \ntrain_generator =train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=PATH_TO_DATA_TRAIN,\n    x_col=\"Images\",\n    y_col=\"Labels\",\n    color_mode='rgb', \n    batch_size=batch_size_train, \n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    subset=\"training\", \n    target_size=(224,224))\n\n\nvalidation_generator=train_datagen.flow_from_dataframe(\n    dataframe=df,\n    directory=PATH_TO_DATA_TRAIN,\n    x_col=\"Images\",\n    y_col=\"Labels\",\n    color_mode='rgb', \n    batch_size=batch_size_test,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    subset=\"validation\",\n    target_size = (224, 224))\n\n\n#validation_generator=train_datagen.flow_from_dataframe(\n#    dataframe=df,\n##    directory=PATH_TO_DATA_TRAIN,\n#    color_mode='rgb', \n#    batch_size=batch_size_test,\n#    class_mode=\"categorical\",\n#    subset='training',\n#    target_size = (224, 224))\n\"\"\"\n","metadata":{"papermill":{"duration":0.040305,"end_time":"2021-10-16T16:47:13.334745","exception":false,"start_time":"2021-10-16T16:47:13.294440","status":"completed"},"scrolled":true,"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# try 32 ->  may go upto 81%, after 3 epoch 79.3%\nbatch_size_train =  32\n\nbatch_size_test = 1\n\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    rotation_range=50,\n    #validation_split = 0.2\n    #validation_split = 0.1\n\n    )\n\n\n\nval_datagen = ImageDataGenerator(\n    rescale=1./255\n    #horizontal_flip=True,\n    #vertical_flip=True,\n    #rotation_range=50,\n    #validation_split = 0.2\n    #validation_split = 0.1\n\n    )\n\n\ntrain_generator =train_datagen.flow_from_directory(\n    #dataframe=df,\n    directory=PATH_TO_DATA_TRAIN,\n    color_mode='rgb', \n    batch_size=batch_size_train, \n    seed=42,\n    shuffle=True,\n    class_mode=\"categorical\",\n    #subset=\"training\", \n    target_size=(224,224))\n\nvalidation_generator=val_datagen.flow_from_directory(\n    #dataframe=df,\n    directory=PATH_TO_DATA_VAL,\n    color_mode='rgb', \n    batch_size=batch_size_test,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    #subset=\"validation\",\n    target_size = (224, 224))\n\ntest_generator=val_datagen.flow_from_directory(\n    #dataframe=df,\n    directory=PATH_TO_DATA_TEST,\n    color_mode='rgb', \n    batch_size=batch_size_test,\n    seed=42,\n    shuffle=False,\n    class_mode=\"categorical\",\n    #subset=\"validation\",\n    target_size = (224, 224))\n\n\n","metadata":{"papermill":{"duration":334.531151,"end_time":"2021-10-16T16:52:47.894264","exception":false,"start_time":"2021-10-16T16:47:13.363113","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#analyze how many in each class \nclasses = ['CC', 'EC', 'LC', 'MC', 'SC'],\n#y_true = validation_generator.classes\n\nmyv = validation_generator.classes;\n\nbin_arr = np.bincount(myv)\nprint(\"validation\", bin_arr)\n\nmyv1 = train_generator.classes;\n\nbin_arr1 = np.bincount(myv1)\nprint(\"training\", bin_arr1)\n\nmyv2 = test_generator.classes;\n\nbin_arr2 = np.bincount(myv2)\nprint(\"test\", bin_arr2)\n\n\n\n#image_batch, label_batch = next(validation_generator)\n#print(label_batch[2])\n#y_CC = validation_generator.count('CC')","metadata":{"papermill":{"duration":0.042957,"end_time":"2021-10-16T16:52:47.966863","exception":false,"start_time":"2021-10-16T16:52:47.923906","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(validation_generator.filenames)\n\n#this is to check if the train set has any images from test set patient\n\n#get a list of all the images in the train set\nfilenames=train_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames})\nresults.to_csv(\"ww42.3_results_train_8.csv\",index=False)\n\n\n#get a list of all the images in the validation set\nfilenames=validation_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames})\nresults.to_csv(\"ww42.3_results_val_8.csv\",index=False)\n\n","metadata":{"papermill":{"duration":0.682498,"end_time":"2021-10-16T16:52:48.679696","exception":false,"start_time":"2021-10-16T16:52:47.997198","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\nimport numpy as np\n\nclass_weights = class_weight.compute_class_weight(\n               'balanced',\n                np.unique(train_generator.classes), \n                train_generator.classes)\nclass_weights = {l:c for l,c in zip(np.unique(train_generator.classes), class_weights)}\n\nprint(class_weights)\n\n#class_weights = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(labels[i]), labels[i])\n#class_weights = {l:c for l,c in zip(np.unique(labels[i]), class_weights)}\n","metadata":{"papermill":{"duration":0.663761,"end_time":"2021-10-16T16:52:49.373458","exception":false,"start_time":"2021-10-16T16:52:48.709697","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef data_visualisation(train_generator\n                      ) -> None:\n    \"\"\"\n    Plot 25 images from one batch\n    \n    train_generator: DirectoryIterator, a train generator that can be obtained from \n                     flow_from_directory in tensorflow.\n    \"\"\"\n    image_batch, label_batch = next(train_generator)\n    classes = np.asarray(list(train_generator.class_indices))\n    #debug \n    #print(classes)\n    \n    plt.figure(figsize=(10,10))\n    for n in range(25):\n        plt.subplot(5,5,n+1)\n        plt.imshow(image_batch[n])\n        plt.title(classes[label_batch[n]==1])\n        plt.axis('off')\n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()\n\n\ndef data_augment_visualisation(train_generator\n                              ) -> None:\n    \"\"\"\n    Plot 5 augmented version of the same image\n    \n    train_generator: DirectoryIterator, a train generator that can be obtained from \n                     flow_from_directory in tensorflow.\n    \"\"\"\n    augmented_images = [train_generator[0][0][0] for i in range(5)]\n    fig, axes = plt.subplots(1, 5, figsize=(10, 10))\n    axes = axes.flatten()\n    for img, ax in zip(augmented_images, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()","metadata":{"papermill":{"duration":0.041931,"end_time":"2021-10-16T16:52:49.445654","exception":false,"start_time":"2021-10-16T16:52:49.403723","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image_batch, label_batch = next(validation_generator)\n#image_batch, label_batch = next(train_generator)\n\n\n\n","metadata":{"papermill":{"duration":0.035569,"end_time":"2021-10-16T16:52:49.511151","exception":false,"start_time":"2021-10-16T16:52:49.475582","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_visualisation(train_generator)","metadata":{"papermill":{"duration":1.915822,"end_time":"2021-10-16T16:52:51.456685","exception":false,"start_time":"2021-10-16T16:52:49.540863","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data_visualisation(validation_generator)","metadata":{"papermill":{"duration":0.051772,"end_time":"2021-10-16T16:52:51.555616","exception":false,"start_time":"2021-10-16T16:52:51.503844","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augment_visualisation(train_generator)","metadata":{"papermill":{"duration":2.082776,"end_time":"2021-10-16T16:52:53.683603","exception":false,"start_time":"2021-10-16T16:52:51.600827","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16\nsource_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))\n\n#from tensorflow.keras.applications.vgg19 import VGG19\n#source_model = VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3))\n","metadata":{"papermill":{"duration":2.582205,"end_time":"2021-10-16T16:52:56.318167","exception":false,"start_time":"2021-10-16T16:52:53.735962","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source_model.summary()","metadata":{"papermill":{"duration":0.071623,"end_time":"2021-10-16T16:52:56.444497","exception":false,"start_time":"2021-10-16T16:52:56.372874","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.models import Model\n\nx = source_model.output\n\nx = Flatten(name='flatten')(x)\n#x = Dense(4096,activation='relu',\n#x = Dense(1024,activation='relu',\n#          kernel_regularizer=l2(1e-4),\n#          name='fc6')(x)\n#x = Dropout(0.5, name='drop6')(x)\n#x = Dense(4096,activation='relu',\nx = Dense(1024,activation='relu',\n          kernel_regularizer=l2(1e-4),\n          name='fc7')(x)\n#x = Dropout(0.5, name='drop7')(x)\n\npreds = Dense(5, activation='softmax', name='prob')(x)\n# Final model: \ntarget_model = Model(inputs=source_model.input, outputs=preds)","metadata":{"papermill":{"duration":0.083627,"end_time":"2021-10-16T16:52:56.581882","exception":false,"start_time":"2021-10-16T16:52:56.498255","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print final model\ntarget_model.summary()","metadata":{"papermill":{"duration":0.072812,"end_time":"2021-10-16T16:52:56.709177","exception":false,"start_time":"2021-10-16T16:52:56.636365","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\n\nopti = SGD(lr=1e-4, momentum=0.9)\n\ntarget_model.compile(optimizer=opti,\n                     loss='categorical_crossentropy', \n                     metrics=['accuracy'])\n\nepochs = 8 ","metadata":{"papermill":{"duration":0.071933,"end_time":"2021-10-16T16:52:56.835663","exception":false,"start_time":"2021-10-16T16:52:56.763730","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('step size:', train_generator.n//train_generator.batch_size)","metadata":{"papermill":{"duration":0.063762,"end_time":"2021-10-16T16:52:56.953710","exception":false,"start_time":"2021-10-16T16:52:56.889948","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# in first epoch around 80% image, stop and run again, immediately \n# reach a high number upto =80% and build to 90% in next epoch\nepochs = 1\nimport time\n\nstart_time = time.time()\n\n\nhistory = target_model.fit(x=train_generator,\n                           steps_per_epoch=train_generator.samples // train_generator.batch_size, \n                           epochs=epochs, \n                           class_weight=class_weights)\n\ntime_elapsed = time.time() - start_time\nprint(\"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))","metadata":{"papermill":{"duration":2976.074582,"end_time":"2021-10-16T17:42:33.083306","exception":false,"start_time":"2021-10-16T16:52:57.008724","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 4\n#epochs = 8\n# Image 7 \n#epochs = 6 \n\n# in first epoch around 80% image, stop and run again, immediately \n# reach a high number upto =80% and build to 90% in next epoch\nimport time\n\nstart_time = time.time()\n\n\nhistory = target_model.fit(x=train_generator,\n                           steps_per_epoch=train_generator.samples // train_generator.batch_size, \n                           epochs=epochs, \n                           class_weight=class_weights)\n\ntime_elapsed = time.time() - start_time\nprint(\"Training complete in {:.0f}m {:.0f}s\".format(time_elapsed // 60, time_elapsed % 60))","metadata":{"papermill":{"duration":10893.318939,"end_time":"2021-10-16T20:44:07.856192","exception":false,"start_time":"2021-10-16T17:42:34.537253","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef history_plot(history\n                ) -> None:\n    \"\"\"\n    Plot the history of the accuracies and losses at each epoch\n    \n    history: history of the training (this is the output of the function 'fit')\n    \"\"\"\n    epochs_range = range(len(history.history['loss']))\n    fig = plt.figure(figsize=(8, 8))\n    \n    # plot of accuracy\n    ax = fig.add_subplot(1, 2, 1)\n    acc = history.history['accuracy']\n    ax.plot(epochs_range, acc)\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Training Accuracy')\n    \n    # plot of loss\n    ax = fig.add_subplot(1, 2, 2)\n    loss = history.history['loss']\n    ax.plot(epochs_range, loss)\n    \n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    \n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()","metadata":{"papermill":{"duration":7.362036,"end_time":"2021-10-16T20:44:22.464556","exception":false,"start_time":"2021-10-16T20:44:15.102520","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_plot(history)","metadata":{"papermill":{"duration":7.676146,"end_time":"2021-10-16T20:44:37.690987","exception":false,"start_time":"2021-10-16T20:44:30.014841","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_model.save('/kaggle/working/target_model_v1.ww42.3_vgg16_32b_72-train_val_test-7_1')","metadata":{"papermill":{"duration":10.306665,"end_time":"2021-10-16T20:44:55.475928","exception":false,"start_time":"2021-10-16T20:44:45.169263","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import tensorflow as tf\n#!ls /kaggle/input/kaggle-data-zoom-transfer-learning-clean\n#path_model_saved = '/kaggle/input/kaggle-data-zoom-transfer-learning-clean/target_model_v1.ww42.3_vgg16_32b_72-train_val_test-8'\n\n#target_model = tf.keras.models.load_model(path_model_saved)\n","metadata":{"papermill":{"duration":7.409317,"end_time":"2021-10-16T20:45:10.538373","exception":false,"start_time":"2021-10-16T20:45:03.129056","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eva = target_model.evaluate(x = validation_generator,\n#                            steps = validation_generator.samples )\n\neva = target_model.evaluate(x = validation_generator,\n                            steps = validation_generator.samples // validation_generator.batch_size)\n","metadata":{"papermill":{"duration":337.713968,"end_time":"2021-10-16T20:50:55.722333","exception":false,"start_time":"2021-10-16T20:45:18.008365","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#eva = target_model.evaluate(x = validation_generator,\n#                            steps = validation_generator.samples )\n\neva = target_model.evaluate(x = test_generator,\n                            steps = test_generator.samples // validation_generator.batch_size)\n","metadata":{"papermill":{"duration":323.832003,"end_time":"2021-10-16T20:56:28.082704","exception":false,"start_time":"2021-10-16T20:51:04.250701","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(eva)","metadata":{"papermill":{"duration":10.755982,"end_time":"2021-10-16T20:56:49.134312","exception":false,"start_time":"2021-10-16T20:56:38.378330","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport pandas as pd\nimport seaborn as sn\nfrom typing import List\nimport numpy as np\nimport pandas.testing as tm\n\ndef plot_confusion_mat(y_true: np.ndarray, \n                       y_pred: np.ndarray, \n                       classes: List[str] = ['CC', 'EC', 'LC', 'MC', 'SC'], \n                       title: str = \"normal\"\n                      ) -> None:\n    \"\"\"\n    Plot the confusion matrix using confusion_matrix function from scikit-learn\n    \n    y_true: true labels, number between 0 to (number of classes-1)\n    y_pred: predicted labels, number between 0 to (number of classes-1)\n    classes: list of the name of all the classes\n    title: name of the experiment\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    df_cm = pd.DataFrame(cm,\n                         index=[i for i in classes],\n                         columns=[i for i in classes])\n    plt.figure(figsize=(10, 7))\n    sn.heatmap(df_cm, annot=True, vmin=0, vmax=400, fmt=\".0f\", annot_kws={'size': 13}, square=True)\n    plt.title(\"Confusion matrix: \"+title)\n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()","metadata":{"papermill":{"duration":10.434553,"end_time":"2021-10-16T20:57:09.937281","exception":false,"start_time":"2021-10-16T20:56:59.502728","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom typing import List\nimport numpy as np\n\ndef plot_AUC_ROC(y_true: np.ndarray, \n                 predictions: np.ndarray, \n                 classes: List[str] = ['CC', 'EC', 'LC', 'MC', 'SC'], \n                 title: str = \"normal\"\n                ) -> None:\n    \"\"\"\n    Plot the AUC-ROC Curve for multiple-classes\n    \n    y_true: true labels, number between 0 to (number of classes-1)\n    predictions: prediction probability for all classes\n    classes: list of the name of all the classes\n    title: name of the experiment\n    \"\"\"\n    num_classes = len(classes)\n    \n    #debug \n    #print(num_classes)\n    y_true = label_binarize(y_true, classes=list(range(num_classes)))\n    for c in range(len(classes)):\n        \n        #debug \n        #print(c)\n        auc_roc = roc_auc_score(y_true[:, c], predictions[:, c])\n        #label = classes[c] + \" AUC: %.3f \" % auc_roc\n        label =  classes[c] +  \" AUC: %.3f\" % auc_roc\n        \n        #debug\n        #print(label)\n\n        a, b, _ = roc_curve(y_true[:, c], predictions[:, c])\n        plt.figure(1, figsize=(7, 7))\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.plot(a, b, label=label)\n        plt.xlabel(\"False positive rate\")\n        plt.ylabel(\"True positive rate\")\n        plt.legend(loc=\"lower right\")\n    plt.title(\"AUC-ROC Curve: \"+title)\n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()","metadata":{"papermill":{"duration":10.408988,"end_time":"2021-10-16T20:57:31.187172","exception":false,"start_time":"2021-10-16T20:57:20.778184","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"classes = ['CC', 'EC', 'LC', 'MC', 'SC'],\nvalidation_generator.reset()\ny_true = validation_generator.classes\n\"\"\"","metadata":{"papermill":{"duration":10.457446,"end_time":"2021-10-16T20:57:52.061708","exception":false,"start_time":"2021-10-16T20:57:41.604262","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#results per (test) train data\nclasses = ['CC', 'EC', 'LC', 'MC', 'SC'],\ntest_generator.reset()\ny_true = test_generator.classes\n\ntest_generator.reset()\npredictions = target_model.predict(x = test_generator, \n                                   steps = test_generator.samples // validation_generator.batch_size)\n#print(predictions)\ny_pred = np.argmax(predictions, axis=1)\n\n#should comment this\nlocal_labels = (test_generator.class_indices)\nlocal_labels = dict((v,k) for k,v in local_labels.items())\nloc_predictions = [local_labels[k] for k in y_pred]\n\n#should comment this\nfilenames=test_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":loc_predictions})\nresults.to_csv(\"ww42.3_results_test_7_1.csv\",index=False)\n","metadata":{"papermill":{"duration":189.997988,"end_time":"2021-10-16T21:01:12.758074","exception":false,"start_time":"2021-10-16T20:58:02.760086","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nplot_confusion_mat(y_true, y_pred, classes, \"ImageNet training all layers  - test\")\nprint(classes)","metadata":{"papermill":{"duration":10.773809,"end_time":"2021-10-16T21:01:33.943951","exception":false,"start_time":"2021-10-16T21:01:23.170142","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['CC', 'EC', 'LC', 'MC', 'SC']\nplot_AUC_ROC(y_true, predictions, classes, \"normal\")","metadata":{"papermill":{"duration":10.799809,"end_time":"2021-10-16T21:01:55.662902","exception":false,"start_time":"2021-10-16T21:01:44.863093","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#results per (test) train data\nclasses = ['CC', 'EC', 'LC', 'MC', 'SC'],\nvalidation_generator.reset()\ny_true = validation_generator.classes\n\nvalidation_generator.reset()\npredictions = target_model.predict(x = validation_generator, \n                                   steps = validation_generator.samples // validation_generator.batch_size)\n#print(predictions)\ny_pred = np.argmax(predictions, axis=1)\n\n#should comment this\nlocal_labels = (validation_generator.class_indices)\nlocal_labels = dict((v,k) for k,v in local_labels.items())\nloc_predictions = [local_labels[k] for k in y_pred]\n\n#should comment this\nfilenames=validation_generator.filenames\nresults=pd.DataFrame({\"Filename\":filenames,\n                      \"Predictions\":loc_predictions})\nresults.to_csv(\"ww42.3results_train_val_test_7_1.csv\",index=False)\n","metadata":{"papermill":{"duration":198.539489,"end_time":"2021-10-16T21:05:24.272269","exception":false,"start_time":"2021-10-16T21:02:05.732780","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(y_true)","metadata":{"papermill":{"duration":10.333113,"end_time":"2021-10-16T21:05:44.986410","exception":false,"start_time":"2021-10-16T21:05:34.653297","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test\n#classes = ['CC', 'MC', 'SC', 'LC', 'EC']\n#auc = 0.923632\n#label = classes[0][4] + \" AUC %.3f\" % auc\n#print(label)","metadata":{"papermill":{"duration":10.913397,"end_time":"2021-10-16T21:06:06.215784","exception":false,"start_time":"2021-10-16T21:05:55.302387","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"validation_generator.reset()\npredictions = target_model.predict(x = validation_generator, \n                                   steps = validation_generator.samples // validation_generator.batch_size)\n#print(predictions)\ny_pred = np.argmax(predictions, axis=1)\n\"\"\"","metadata":{"papermill":{"duration":10.274884,"end_time":"2021-10-16T21:06:26.858254","exception":false,"start_time":"2021-10-16T21:06:16.583370","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#should comment this\n#local_labels = (validation_generator.class_indices)\n#local_labels = dict((v,k) for k,v in local_labels.items())\n#predictions_local = [local_labels[k] for k in y_pred]\n","metadata":{"papermill":{"duration":10.378543,"end_time":"2021-10-16T21:06:48.156758","exception":false,"start_time":"2021-10-16T21:06:37.778215","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#should comment this\n#filenames=validation_generator.filenames\n#results=pd.DataFrame({\"Filename\":filenames,\n#                      \"Predictions\":predictions_local})\n#results.to_csv(\"results.csv\",index=False)","metadata":{"papermill":{"duration":10.874968,"end_time":"2021-10-16T21:07:09.372646","exception":false,"start_time":"2021-10-16T21:06:58.497678","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(y_pred)","metadata":{"papermill":{"duration":10.328584,"end_time":"2021-10-16T21:07:30.218893","exception":false,"start_time":"2021-10-16T21:07:19.890309","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nplot_confusion_mat(y_true, y_pred, classes, \"ImageNet training all layers -val\")\nprint(classes)","metadata":{"papermill":{"duration":10.790511,"end_time":"2021-10-16T21:07:51.894938","exception":false,"start_time":"2021-10-16T21:07:41.104427","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ['CC', 'EC', 'LC', 'MC', 'SC']\nplot_AUC_ROC(y_true, predictions, classes, \"normal\")","metadata":{"papermill":{"duration":11.434929,"end_time":"2021-10-16T21:08:13.658651","exception":false,"start_time":"2021-10-16T21:08:02.223722","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}